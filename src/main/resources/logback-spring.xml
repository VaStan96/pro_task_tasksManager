<configuration>
    <appender name="kafka" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <!-- <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
            <pattern>{"timestamp":"%d{ISO8601}", "service":"Tasks-Service", "level":"%-5level", "logger":"%logger{36}", "message":"%msg"}%n</pattern>
        </encoder> -->
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"service": "Tasks-Service"}</customFields>
        </encoder>
        
        <topic>logs</topic>
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>
        
        <!-- bootstrap.servers is the only mandatory producerConfig -->
        <producerConfig>bootstrap.servers=kafka:9092</producerConfig>
        <!-- don't wait for a broker to ack the reception of a batch.  -->
        <producerConfig>acks=0</producerConfig>
        <!-- wait up to 1000ms and collect log messages before sending them as a batch -->
        <producerConfig>linger.ms=1000</producerConfig>
        <!-- even if the producer buffer runs full, do not block the application but start to drop messages -->
        <producerConfig>max.block.ms=0</producerConfig>
   </appender>

    <root level="INFO">
        <appender-ref ref="kafka"/>
    </root>
</configuration>